{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data] Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package genesis to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/genesis.zip.\n",
      "[nltk_data] Downloading package inaugural to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data] Downloading package nps_chat to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data] Downloading package treebank to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n",
      "[nltk_data] Downloading package udhr to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/udhr.zip.\n",
      "[nltk_data] Downloading package webtext to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/webtext.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('genesis')\n",
    "\n",
    "nltk.download('inaugural')\n",
    "\n",
    "nltk.download('nps_chat')\n",
    "\n",
    "nltk.download('treebank')\n",
    "\n",
    "nltk.download('udhr')\n",
    "\n",
    "nltk.download('webtext')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254989, 260819)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(nltk.word_tokenize(moby_raw)),len(text1)\n",
    "\n",
    "example_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20755"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16900,\n",
       " {'Watching',\n",
       "  '98',\n",
       "  'human',\n",
       "  'remember',\n",
       "  'fluke',\n",
       "  'bearskin',\n",
       "  'intrepidly',\n",
       "  'easy-going',\n",
       "  'rider',\n",
       "  'kill',\n",
       "  'via',\n",
       "  'Gros',\n",
       "  'inhabitable',\n",
       "  'stall-fed',\n",
       "  '110',\n",
       "  'screw-driver',\n",
       "  'reform',\n",
       "  'startlingly',\n",
       "  'ghost-devil',\n",
       "  'exclusiveness',\n",
       "  'quahogs',\n",
       "  'bed-side',\n",
       "  'right-angles',\n",
       "  'Where',\n",
       "  'Stern',\n",
       "  'probably',\n",
       "  'revengeful',\n",
       "  'manifest',\n",
       "  'wit',\n",
       "  'trance',\n",
       "  'Meets',\n",
       "  'sylphs',\n",
       "  'thigh-board',\n",
       "  'betakes',\n",
       "  'pre-eminently',\n",
       "  'overture',\n",
       "  'incarnation',\n",
       "  'principle',\n",
       "  'Connecticut',\n",
       "  'arctic',\n",
       "  'eleven',\n",
       "  'mast-heads',\n",
       "  'crystalline',\n",
       "  'Measurement',\n",
       "  'visitations',\n",
       "  'Manhatto',\n",
       "  'mystery',\n",
       "  'ungentlemanly',\n",
       "  'nail-filers',\n",
       "  'eye',\n",
       "  'sea-sofa',\n",
       "  'impeach',\n",
       "  'unpanelled',\n",
       "  'Fejee',\n",
       "  'trope',\n",
       "  'prompt',\n",
       "  'innumerable',\n",
       "  'irradiate',\n",
       "  'germs',\n",
       "  'discount',\n",
       "  'dictator',\n",
       "  'clearness',\n",
       "  'grudge',\n",
       "  'conspicuously',\n",
       "  'impregnate',\n",
       "  'topic',\n",
       "  'gently',\n",
       "  'voluntary',\n",
       "  'fanciful',\n",
       "  'intellects',\n",
       "  'cloth-covered',\n",
       "  'Sovereign',\n",
       "  'Leap',\n",
       "  'glass',\n",
       "  'live-oaks',\n",
       "  'vortices',\n",
       "  'drown',\n",
       "  'performances',\n",
       "  'barnacled',\n",
       "  'deceits',\n",
       "  'housekeepers',\n",
       "  'although',\n",
       "  'twenty-five',\n",
       "  'Wheelbarrow',\n",
       "  'stitch',\n",
       "  'thoroughly',\n",
       "  'god',\n",
       "  'Dome',\n",
       "  'terse',\n",
       "  'pop',\n",
       "  'Cloud',\n",
       "  'moles',\n",
       "  'unsafe',\n",
       "  'Rope',\n",
       "  'price',\n",
       "  'excitements',\n",
       "  'naturalists',\n",
       "  'islanders',\n",
       "  'lot',\n",
       "  'ideality',\n",
       "  'intolerably',\n",
       "  'guilt',\n",
       "  'convert',\n",
       "  'loud',\n",
       "  'Off',\n",
       "  'oily',\n",
       "  'calculate',\n",
       "  'EMBONPOINT',\n",
       "  'disease',\n",
       "  'Cutting',\n",
       "  'linear',\n",
       "  'savor',\n",
       "  \"'S\",\n",
       "  'spring-head',\n",
       "  'whom',\n",
       "  'insane',\n",
       "  'where',\n",
       "  'larboard',\n",
       "  'joyously',\n",
       "  'prematurely',\n",
       "  'Starbuck',\n",
       "  'stoutest',\n",
       "  'head-and-head',\n",
       "  \"boat's\",\n",
       "  'Years',\n",
       "  'confuse',\n",
       "  'medallion-shaped',\n",
       "  'babble',\n",
       "  'weather-sheet',\n",
       "  'unthinkingly',\n",
       "  'street',\n",
       "  'same',\n",
       "  'squadrons',\n",
       "  'whaling-ships',\n",
       "  'demon',\n",
       "  'Patagonia',\n",
       "  'unnaturally',\n",
       "  'telegraph',\n",
       "  'carefully',\n",
       "  'acquiesce',\n",
       "  'intention',\n",
       "  '129',\n",
       "  'Days',\n",
       "  \"heart's\",\n",
       "  'cylinders',\n",
       "  'unwarranted',\n",
       "  'proverbial',\n",
       "  'Jinglers',\n",
       "  'Cassock',\n",
       "  'peculiar',\n",
       "  'joint-owners',\n",
       "  'horribles',\n",
       "  'Symphony',\n",
       "  'far',\n",
       "  'remind',\n",
       "  'portent',\n",
       "  'Heart',\n",
       "  'BOUTON',\n",
       "  'Lit',\n",
       "  'gobern',\n",
       "  'hamlets',\n",
       "  'coerce',\n",
       "  'Rig',\n",
       "  'diminish',\n",
       "  'conceit',\n",
       "  'lug',\n",
       "  'equinox',\n",
       "  \"know'st\",\n",
       "  'translation',\n",
       "  'unsubstantial',\n",
       "  'Belisarius',\n",
       "  'rover',\n",
       "  'scratch',\n",
       "  'aright',\n",
       "  'Genesis',\n",
       "  'objectionable',\n",
       "  'head-laden',\n",
       "  'unclothe',\n",
       "  'Blang-whang',\n",
       "  'drought',\n",
       "  'Smeer',\n",
       "  'peasants',\n",
       "  'creepingly',\n",
       "  'omnipotent',\n",
       "  'SISTER',\n",
       "  'bleakness',\n",
       "  'FIGURED',\n",
       "  'Arsacides',\n",
       "  'double-jointed',\n",
       "  'Slip',\n",
       "  'rudely',\n",
       "  'enable',\n",
       "  'bridegroom',\n",
       "  \"'Stop\",\n",
       "  'conceptions',\n",
       "  'Scoresby',\n",
       "  'unreliable',\n",
       "  '*It',\n",
       "  'half-cut',\n",
       "  'Elbe',\n",
       "  'hearth-stone',\n",
       "  'bias',\n",
       "  'tomahawk-pipe',\n",
       "  'pointless',\n",
       "  'comfortably',\n",
       "  'mackerel',\n",
       "  'Raise',\n",
       "  'circumstanced',\n",
       "  'worthy',\n",
       "  'Mogulship',\n",
       "  'superficially',\n",
       "  'jeopardize',\n",
       "  'supply',\n",
       "  'recollect',\n",
       "  'canonicals',\n",
       "  'PASSING',\n",
       "  'Vesuvius',\n",
       "  'pruning-hook',\n",
       "  'restless',\n",
       "  'chaplain',\n",
       "  'new-built',\n",
       "  'endurance',\n",
       "  'painter',\n",
       "  'spite',\n",
       "  'whereon',\n",
       "  'rudimental',\n",
       "  'garter',\n",
       "  'lath',\n",
       "  'offices',\n",
       "  'surcoat',\n",
       "  'humanities',\n",
       "  'Fill',\n",
       "  'primitive',\n",
       "  'interruptions',\n",
       "  'magnification',\n",
       "  'combinedly',\n",
       "  'above',\n",
       "  'trencher',\n",
       "  'country-bred',\n",
       "  'uncompromisedness',\n",
       "  'crest',\n",
       "  'intelligent',\n",
       "  'raft',\n",
       "  'Presbyterians',\n",
       "  'Dugongs',\n",
       "  'money',\n",
       "  'cabin',\n",
       "  'incoherently',\n",
       "  'Air',\n",
       "  'susceptible',\n",
       "  'Republican',\n",
       "  'mayst',\n",
       "  'poets',\n",
       "  'gentlemanlike',\n",
       "  'contract',\n",
       "  'ISOLATO',\n",
       "  'superfluous',\n",
       "  'husk',\n",
       "  'professors',\n",
       "  'darker',\n",
       "  'impel',\n",
       "  'scythe',\n",
       "  'WATCH',\n",
       "  'Loaded',\n",
       "  'spool',\n",
       "  'Plum-pudding',\n",
       "  'LENGTHWISE',\n",
       "  'godly-looking',\n",
       "  'largeness',\n",
       "  'reprehensible',\n",
       "  'Sheffield',\n",
       "  'Anacharsis',\n",
       "  'crack',\n",
       "  'draft',\n",
       "  'vexatious',\n",
       "  'quilt',\n",
       "  'profit',\n",
       "  'Trade',\n",
       "  'signify',\n",
       "  'wherewith',\n",
       "  'fang',\n",
       "  'turbid',\n",
       "  'expansion',\n",
       "  'years',\n",
       "  'Cough',\n",
       "  'Spirit',\n",
       "  \"pilot's\",\n",
       "  'nurture',\n",
       "  'hemlock',\n",
       "  'government',\n",
       "  'cupola',\n",
       "  'Newfoundland',\n",
       "  'scenery',\n",
       "  'crow',\n",
       "  'U.',\n",
       "  'lion-like',\n",
       "  'history',\n",
       "  'inadequately',\n",
       "  'skulls',\n",
       "  'Pope',\n",
       "  'bandage',\n",
       "  '5TH',\n",
       "  'ejaculation',\n",
       "  'intimation',\n",
       "  'firm-seated',\n",
       "  'whale-hater',\n",
       "  'Leviathans',\n",
       "  'resolutely',\n",
       "  'baser',\n",
       "  'huge',\n",
       "  'Trumpa',\n",
       "  'each',\n",
       "  'ragamuffin',\n",
       "  \"'Bout\",\n",
       "  'bristle',\n",
       "  'notoriety',\n",
       "  'view',\n",
       "  'Holland',\n",
       "  'andirons',\n",
       "  'humorous',\n",
       "  'subtly',\n",
       "  'hallucination',\n",
       "  'desperation',\n",
       "  'Barrens',\n",
       "  'analogies',\n",
       "  \"'ll\",\n",
       "  'contrive',\n",
       "  'revenue',\n",
       "  'eighty',\n",
       "  'framework',\n",
       "  'whither',\n",
       "  'Newcastle',\n",
       "  'transom',\n",
       "  'bedside',\n",
       "  'Dance',\n",
       "  'dissimilar',\n",
       "  'conductor',\n",
       "  'reliable',\n",
       "  'Buckets',\n",
       "  'attainable',\n",
       "  '1',\n",
       "  'silent',\n",
       "  'surrenderest',\n",
       "  'workers',\n",
       "  'life-restless',\n",
       "  'inconsiderable',\n",
       "  'dandy',\n",
       "  'document',\n",
       "  'manifesto',\n",
       "  'searchingly',\n",
       "  'amazement',\n",
       "  'doubloon',\n",
       "  'NOUN',\n",
       "  'ridge-pole',\n",
       "  'filliping',\n",
       "  'seat',\n",
       "  'Marius',\n",
       "  \"'Take\",\n",
       "  'unsubduable',\n",
       "  'mad',\n",
       "  'Hurriedly',\n",
       "  'Cruppered',\n",
       "  'Terrible',\n",
       "  'half-hinting',\n",
       "  'Rio',\n",
       "  'wan',\n",
       "  'Preternatural',\n",
       "  'pen-knife',\n",
       "  'brushwood',\n",
       "  'hunch',\n",
       "  'Auto-da-Fe',\n",
       "  'scan',\n",
       "  'baggage',\n",
       "  'chance-like',\n",
       "  'remonstrate',\n",
       "  'High',\n",
       "  'Riotous',\n",
       "  'mahogany',\n",
       "  'ocean-perishing',\n",
       "  'homewards',\n",
       "  'Shakers',\n",
       "  'steward',\n",
       "  'dam-me',\n",
       "  'Boomer',\n",
       "  'demoniac',\n",
       "  'unexaggerated',\n",
       "  'tree',\n",
       "  'embrace',\n",
       "  'scant',\n",
       "  'fountain',\n",
       "  'glazier',\n",
       "  'knives',\n",
       "  'felonious',\n",
       "  'perverse',\n",
       "  'divulge',\n",
       "  'depressions',\n",
       "  'cannibally',\n",
       "  'neck',\n",
       "  'lotions',\n",
       "  'vengeance',\n",
       "  'half-melted',\n",
       "  'rest',\n",
       "  'scowl',\n",
       "  'stash',\n",
       "  'all',\n",
       "  'straits',\n",
       "  'holders',\n",
       "  'THOMAS',\n",
       "  'drop',\n",
       "  'mute',\n",
       "  \"day's\",\n",
       "  'separate',\n",
       "  'belay',\n",
       "  \"Would'st\",\n",
       "  'monomaniac',\n",
       "  'wharf',\n",
       "  'ruggedest',\n",
       "  'well-saved',\n",
       "  'slash',\n",
       "  'violently',\n",
       "  'entitle',\n",
       "  'quarrel',\n",
       "  'His',\n",
       "  'bamboo',\n",
       "  'trial',\n",
       "  'remoter',\n",
       "  'frustrate',\n",
       "  'palmy',\n",
       "  'prominence',\n",
       "  'Hollanders',\n",
       "  'Koo-loo',\n",
       "  'lightly',\n",
       "  'Sicilian',\n",
       "  'instance',\n",
       "  'sallied',\n",
       "  'dear',\n",
       "  'Quitting',\n",
       "  'week',\n",
       "  'meridians',\n",
       "  'broad-shouldered',\n",
       "  'invincible',\n",
       "  'seclude',\n",
       "  'capacity',\n",
       "  'angels',\n",
       "  'nearly',\n",
       "  'sky-born',\n",
       "  'exasperations',\n",
       "  'IVORY',\n",
       "  'bake-houses',\n",
       "  'must',\n",
       "  'overhear',\n",
       "  'Mammoth',\n",
       "  'apoplectic',\n",
       "  'thole-pins',\n",
       "  'inquiries',\n",
       "  'six',\n",
       "  'WITH',\n",
       "  'active',\n",
       "  'redundant',\n",
       "  'mildly',\n",
       "  'Euclid',\n",
       "  'Goodwin',\n",
       "  'undrape',\n",
       "  'rapacious',\n",
       "  'peradventure',\n",
       "  'Nat',\n",
       "  'things',\n",
       "  'associations',\n",
       "  'white-bone',\n",
       "  'flock',\n",
       "  'repose',\n",
       "  '51',\n",
       "  'NEWSPAPER',\n",
       "  'ignite',\n",
       "  'Herman',\n",
       "  'Amsterdam',\n",
       "  'iron',\n",
       "  'boat-header',\n",
       "  'phenomena',\n",
       "  'Presently',\n",
       "  'glisten',\n",
       "  'genealogy',\n",
       "  'helpless',\n",
       "  'fiercely',\n",
       "  'Companies',\n",
       "  'opinion',\n",
       "  'faculties',\n",
       "  'Small',\n",
       "  'barnacle',\n",
       "  'Under',\n",
       "  'appointments',\n",
       "  'Science',\n",
       "  'coolly',\n",
       "  'peg',\n",
       "  'adoration',\n",
       "  'echo',\n",
       "  'dumbest',\n",
       "  'TAKEN',\n",
       "  'unaccountably',\n",
       "  'Afterwards',\n",
       "  \"person's\",\n",
       "  'interrupt',\n",
       "  'predominate',\n",
       "  'museum',\n",
       "  'highway',\n",
       "  'unfurnished',\n",
       "  'top-sails',\n",
       "  'invasion',\n",
       "  'casualty',\n",
       "  'my',\n",
       "  'ninety-six',\n",
       "  \"Thou'st\",\n",
       "  'young',\n",
       "  'western',\n",
       "  'innuendoes',\n",
       "  'oblivious',\n",
       "  'flower-market',\n",
       "  'tu',\n",
       "  'away',\n",
       "  'absent-minded',\n",
       "  'text',\n",
       "  'residue',\n",
       "  'Icebergs',\n",
       "  'yawingly',\n",
       "  \"'s\",\n",
       "  'WHALES',\n",
       "  'Such',\n",
       "  'Chartering',\n",
       "  'correctly',\n",
       "  '81',\n",
       "  '43',\n",
       "  'incarcerate',\n",
       "  'cheap',\n",
       "  'piazza',\n",
       "  'soap',\n",
       "  'Laws',\n",
       "  'steer',\n",
       "  'customary',\n",
       "  'Dissect',\n",
       "  'comprehension',\n",
       "  'Dragged',\n",
       "  'African',\n",
       "  'Entering',\n",
       "  'nap',\n",
       "  'fabled',\n",
       "  'Stick',\n",
       "  'Commend',\n",
       "  'frightful',\n",
       "  'freedom',\n",
       "  'egg',\n",
       "  'picture',\n",
       "  'YORK',\n",
       "  'superiors',\n",
       "  'interlude',\n",
       "  'Gay',\n",
       "  'devilish',\n",
       "  'Twice',\n",
       "  \"could'st\",\n",
       "  'dauntlessness',\n",
       "  'publish',\n",
       "  \"'that\",\n",
       "  'steam-engines',\n",
       "  'Possession',\n",
       "  'drunken',\n",
       "  'torso',\n",
       "  'Tropics',\n",
       "  'meditation',\n",
       "  'Cursed',\n",
       "  'Whale-bone',\n",
       "  \"that's\",\n",
       "  'deliriously',\n",
       "  'immovable',\n",
       "  'full-grown',\n",
       "  'Startled',\n",
       "  'Look-e',\n",
       "  'Milky',\n",
       "  'Whirlpooles',\n",
       "  'dance',\n",
       "  'breathless',\n",
       "  'manifold',\n",
       "  'stark',\n",
       "  'destine',\n",
       "  'unvexed',\n",
       "  'outworks',\n",
       "  'EYES',\n",
       "  'spiritually',\n",
       "  'eloquent',\n",
       "  'outlet',\n",
       "  'confession',\n",
       "  'Emperor',\n",
       "  'HERBERT',\n",
       "  'elope',\n",
       "  'flasks',\n",
       "  'unpleasing',\n",
       "  'short-warp',\n",
       "  'whale-spades',\n",
       "  'exhume',\n",
       "  'man-rope',\n",
       "  'inheritor',\n",
       "  'scroll',\n",
       "  'whalesmen',\n",
       "  'gallied',\n",
       "  'wager',\n",
       "  'Decanter',\n",
       "  'Myself',\n",
       "  'chamber-maid',\n",
       "  'begrime',\n",
       "  'robustness',\n",
       "  'Timor',\n",
       "  'unstirring',\n",
       "  'habeat',\n",
       "  'sidelingly',\n",
       "  'Rafters',\n",
       "  'impetus',\n",
       "  'army',\n",
       "  'undeliverable',\n",
       "  'topsails',\n",
       "  '400,000',\n",
       "  'nod',\n",
       "  'gurgle',\n",
       "  'hillock',\n",
       "  'touch',\n",
       "  'food',\n",
       "  'accustom',\n",
       "  'shaggy',\n",
       "  'fattest',\n",
       "  'docile',\n",
       "  'Assuredly',\n",
       "  'diametrically',\n",
       "  'blubber-hunters',\n",
       "  'gallantry',\n",
       "  'Esau',\n",
       "  'screwed-down',\n",
       "  'unblinkingly',\n",
       "  'comber',\n",
       "  'cajole',\n",
       "  'office',\n",
       "  'fa',\n",
       "  'plummet',\n",
       "  'atheistical',\n",
       "  'geometry',\n",
       "  'rout',\n",
       "  'venison',\n",
       "  'annihilate',\n",
       "  'freight',\n",
       "  'card',\n",
       "  'porthole',\n",
       "  \"a'ready\",\n",
       "  'bust',\n",
       "  'stomach',\n",
       "  \"whalemen's\",\n",
       "  'transport',\n",
       "  'cynical',\n",
       "  'pirate',\n",
       "  'drab-coloured',\n",
       "  'protrusion',\n",
       "  'Comparing',\n",
       "  'bankers',\n",
       "  'noblemen',\n",
       "  'shepherd',\n",
       "  'Work',\n",
       "  'mountainous',\n",
       "  'tuck',\n",
       "  'tranquilly',\n",
       "  'castor',\n",
       "  'sleepiest',\n",
       "  'Brighggians',\n",
       "  'wight',\n",
       "  'chalices',\n",
       "  'spar',\n",
       "  'rove',\n",
       "  'CANNY',\n",
       "  'carrion',\n",
       "  'GENERALLY',\n",
       "  'haze',\n",
       "  'gate',\n",
       "  'themselves',\n",
       "  'two',\n",
       "  'refuse',\n",
       "  'sight-tubes',\n",
       "  'whirl',\n",
       "  'worldly',\n",
       "  'ticklish',\n",
       "  'DAGGOO',\n",
       "  'brides',\n",
       "  'magnetic',\n",
       "  'non-valvular',\n",
       "  'shagginess',\n",
       "  'persevere',\n",
       "  'honourable',\n",
       "  'noblest',\n",
       "  'design',\n",
       "  'persons',\n",
       "  'Skeleton',\n",
       "  'well-earned',\n",
       "  'salutations',\n",
       "  'seventy-fours',\n",
       "  'matter',\n",
       "  'up',\n",
       "  'water-gazers',\n",
       "  'dividends',\n",
       "  'book-binder',\n",
       "  'brigness',\n",
       "  'Italy',\n",
       "  'forethrown',\n",
       "  'SCORESBY',\n",
       "  'stare',\n",
       "  'marsh',\n",
       "  'towns',\n",
       "  'unyielding',\n",
       "  'conduct',\n",
       "  'snore',\n",
       "  'poor-box',\n",
       "  'Vancouver',\n",
       "  'slew',\n",
       "  'conveyance',\n",
       "  'THUS',\n",
       "  'yards',\n",
       "  'ditchers',\n",
       "  'prop',\n",
       "  'authorize',\n",
       "  'half-formed',\n",
       "  'oneness',\n",
       "  'flints',\n",
       "  'loggerheads',\n",
       "  'Five',\n",
       "  'undiluted',\n",
       "  'ruefully',\n",
       "  'farthingale',\n",
       "  'dismay',\n",
       "  'events',\n",
       "  '39',\n",
       "  'tide-rip',\n",
       "  'Chinese',\n",
       "  'MATE',\n",
       "  'possession',\n",
       "  'hairy',\n",
       "  'amphitheatrical',\n",
       "  'timidity',\n",
       "  'Cant',\n",
       "  'indicate',\n",
       "  'LONG-ISLAND',\n",
       "  'blubber-room',\n",
       "  'pine',\n",
       "  'reciprocal',\n",
       "  'sleights',\n",
       "  'brag',\n",
       "  \"ECKERMANN'S\",\n",
       "  'Folios',\n",
       "  'tranquillities',\n",
       "  'wet',\n",
       "  'German',\n",
       "  'Bildad',\n",
       "  'And',\n",
       "  'swindle',\n",
       "  'ancient',\n",
       "  'mossy',\n",
       "  'sultanism',\n",
       "  'spaciousness',\n",
       "  'Gothic',\n",
       "  'glens',\n",
       "  'debtor',\n",
       "  'everybody',\n",
       "  'Pots',\n",
       "  'jury-masts',\n",
       "  'stow',\n",
       "  'besiege',\n",
       "  'unapparent',\n",
       "  'unconditional',\n",
       "  'Signals',\n",
       "  'Pardon',\n",
       "  'Immediately',\n",
       "  'gabled',\n",
       "  'Squires',\n",
       "  'Maury',\n",
       "  'inherent',\n",
       "  'liken',\n",
       "  'snow-shoes',\n",
       "  \"world's\",\n",
       "  \"Plato's\",\n",
       "  'SURE',\n",
       "  'turtle-balls',\n",
       "  'leviathan',\n",
       "  'confluent',\n",
       "  'Night',\n",
       "  'bland',\n",
       "  'pond',\n",
       "  'Stars',\n",
       "  'triangularly',\n",
       "  'hamper',\n",
       "  'pilot-fee',\n",
       "  'heart-stricken',\n",
       "  'impersonal',\n",
       "  'Thee',\n",
       "  'Crozetts',\n",
       "  'hath',\n",
       "  'federate',\n",
       "  'almanac',\n",
       "  'anchor',\n",
       "  'half-stupidly',\n",
       "  'marvel',\n",
       "  'half-suspended',\n",
       "  'victorious',\n",
       "  'SPERMA',\n",
       "  'frequently',\n",
       "  'select',\n",
       "  'Fasting',\n",
       "  'uncouthness',\n",
       "  'Pretty',\n",
       "  'harpooneer',\n",
       "  'deeds',\n",
       "  'wealthiest',\n",
       "  'broad',\n",
       "  'cabin-compass',\n",
       "  'because',\n",
       "  'woraciousness',\n",
       "  'fadeless',\n",
       "  'row',\n",
       "  'According',\n",
       "  'judiciously',\n",
       "  'establishment',\n",
       "  'probable',\n",
       "  'Usually',\n",
       "  'hazel',\n",
       "  'excite',\n",
       "  'boot',\n",
       "  'rascals',\n",
       "  '49',\n",
       "  'archaeologists',\n",
       "  'Blind',\n",
       "  'needle',\n",
       "  'nonce',\n",
       "  'draggingly',\n",
       "  'delight',\n",
       "  'wavingly',\n",
       "  'seal',\n",
       "  'Requiem',\n",
       "  'independence',\n",
       "  'lavish',\n",
       "  'confound',\n",
       "  'whip',\n",
       "  'institute',\n",
       "  'brother',\n",
       "  '84',\n",
       "  'musk-scented',\n",
       "  'establish',\n",
       "  'outcry',\n",
       "  'constantly',\n",
       "  'trebly',\n",
       "  'competency',\n",
       "  'godly',\n",
       "  'good-natured',\n",
       "  '1775',\n",
       "  'milky',\n",
       "  'village',\n",
       "  'rude',\n",
       "  'Rockaway',\n",
       "  'valise',\n",
       "  'carlines',\n",
       "  'machinery',\n",
       "  'current',\n",
       "  'circumference',\n",
       "  'milestones',\n",
       "  'Clearing',\n",
       "  'wane',\n",
       "  'emprise',\n",
       "  'metallic-like',\n",
       "  'absolutely',\n",
       "  'groves',\n",
       "  'cypher',\n",
       "  'Fine',\n",
       "  'smuggle',\n",
       "  'Joy',\n",
       "  'unbegotten',\n",
       "  'cutting-tackles',\n",
       "  'prow',\n",
       "  'fortune',\n",
       "  \"'Adios\",\n",
       "  'pagoda-looking',\n",
       "  'unflinching',\n",
       "  'immemorially',\n",
       "  'obscure',\n",
       "  'van',\n",
       "  'conflagrations',\n",
       "  'foggy',\n",
       "  'self-command',\n",
       "  'Tell',\n",
       "  'finish',\n",
       "  'Business',\n",
       "  'gardenny',\n",
       "  'hearty',\n",
       "  'leapest',\n",
       "  'Heeva-Heeva',\n",
       "  'strictly',\n",
       "  'Muffled',\n",
       "  'oars',\n",
       "  'clefts',\n",
       "  'Lord',\n",
       "  'Sounding',\n",
       "  'vinegar-cruet',\n",
       "  'undetached',\n",
       "  'Rising',\n",
       "  'Hussey',\n",
       "  'bisons',\n",
       "  'ounce',\n",
       "  'apeak',\n",
       "  'nervously',\n",
       "  'hideousness',\n",
       "  'crimson',\n",
       "  'paregoric',\n",
       "  'irresolution',\n",
       "  'type',\n",
       "  'Betty',\n",
       "  'systematization',\n",
       "  'pour',\n",
       "  \"crow's-nest\",\n",
       "  'yard-arm',\n",
       "  'horse-pieces',\n",
       "  'bill-fish',\n",
       "  'mouthful',\n",
       "  'thunder-boom',\n",
       "  'prevalent',\n",
       "  'BREACH',\n",
       "  'protrude',\n",
       "  'sanctum',\n",
       "  'warrantry',\n",
       "  'magnetize',\n",
       "  'sarmon',\n",
       "  'foolish',\n",
       "  'ginger-jub',\n",
       "  'cherubim',\n",
       "  'rifle',\n",
       "  'Locks',\n",
       "  'everywhere',\n",
       "  'verbally',\n",
       "  'contrary',\n",
       "  'zay',\n",
       "  'hay-making',\n",
       "  \"would'st\",\n",
       "  'shad',\n",
       "  'equanimity',\n",
       "  'Brace',\n",
       "  'main-sail',\n",
       "  'miraculous',\n",
       "  'bridge',\n",
       "  'combat',\n",
       "  'Prometheus',\n",
       "  'overrunningly',\n",
       "  'uninterrupted',\n",
       "  'danger',\n",
       "  'expressly',\n",
       "  'spirit',\n",
       "  'Siamese',\n",
       "  'limbs',\n",
       "  'diet',\n",
       "  'Whaleman',\n",
       "  'off',\n",
       "  'occupants',\n",
       "  'slowly',\n",
       "  'inter-indebtedness',\n",
       "  'cymballing',\n",
       "  'depend',\n",
       "  'metaphysically',\n",
       "  'Queen-pinmoney',\n",
       "  'secret',\n",
       "  'deem',\n",
       "  'wildest',\n",
       "  'half-starved',\n",
       "  'FLAME',\n",
       "  'humph',\n",
       "  'mock',\n",
       "  'ivory-inlaid',\n",
       "  'cork-screws',\n",
       "  'liturgies',\n",
       "  'hum',\n",
       "  'Against',\n",
       "  'thickly',\n",
       "  'platform',\n",
       "  'Quebec',\n",
       "  'victory',\n",
       "  'gag',\n",
       "  'hang',\n",
       "  'quills',\n",
       "  'twin-jets',\n",
       "  'undertaker',\n",
       "  'daybreak',\n",
       "  'procedure',\n",
       "  'shock',\n",
       "  'dress',\n",
       "  'wrists',\n",
       "  'mid-winter',\n",
       "  'perquisites',\n",
       "  'Astern',\n",
       "  'half-hissed',\n",
       "  'Bress',\n",
       "  'poverty-stricken',\n",
       "  'sail',\n",
       "  'Leyden',\n",
       "  'steel-like',\n",
       "  'Whale-ships',\n",
       "  ...})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return len(set(lemmatized)),set(lemmatized)\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08139566804842562"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    results =len(set(moby_tokens))/len(text1)\n",
    "\n",
    "    return results\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4125668166077752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    mobf_freq = FreqDist(moby_tokens)\n",
    "    whales = mobf_freq['whale'] + mobf_freq['Whale']\n",
    "    total = len(moby_tokens)\n",
    "    return whales*100/total\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    dist = (FreqDist(moby_tokens))\n",
    "    \n",
    "    return dist.most_common(20)# Your answer here\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return an alphabetically sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    \n",
    "    mobF = FreqDist(moby_tokens)\n",
    "    word = [w for w in text1 if (mobF[w]>150) & (len(w)>5)]\n",
    "    word = sorted(set(word))\n",
    "    return word# Your answer here\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "def answer_five():\n",
    "    nums=[]\n",
    "    for w in moby_tokens:\n",
    "        n = len(w)\n",
    "        nums.append(n)\n",
    "    dic = dict(zip(moby_tokens,nums))\n",
    "    long = sorted(dic.items(), key=operator.itemgetter(1),reverse=True)[0]\n",
    "    \n",
    "    return long\n",
    "\n",
    "answer_five()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2097, 'I')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    moby_frequencies = FreqDist(moby_tokens)\n",
    "    moby_frequency_frame = pd.DataFrame(moby_frequencies.most_common(),columns=['token','frequency'])\n",
    "    moby_words = moby_frequency_frame[moby_frequency_frame.token.str.isalpha()]\n",
    "    common = moby_words[moby_words['frequency']>2000]\n",
    "    return list(zip(common['frequency'],common['token']))\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.881952902963864"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(moby_raw)\n",
    "    num = (len(nltk.word_tokenize(s)) for s in sentences)\n",
    "    avg = sum(num)/len(sentences)\n",
    "    return avg# Your answer here\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 3944), ('JJ', 2958), ('NNP', 2950), ('NNS', 2420), ('VBG', 1402)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    moby_frequencies = FreqDist(moby_tokens)\n",
    "    moby_frequency_frame = pd.DataFrame(moby_frequencies.most_common(),columns=['token','frequency'])\n",
    "    moby_words = moby_frequency_frame[moby_frequency_frame['token'].str.isalpha()]    \n",
    "    labels = nltk.pos_tag(moby_words.token)\n",
    "    freq = FreqDist([label for (word,label) in labels])\n",
    "    return freq.most_common(5)# Your answer here\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "from nltk.metrics.distance import (edit_distance, jaccard_distance)\n",
    "from nltk.util import ngrams\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_words = words.words()\n",
    "correct_series = pd.Series(correct_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    gram_num = 3\n",
    "    recommendations = []\n",
    "    for entry in entries:\n",
    "        words = correct_series[correct_series.str.startswith(entry[0])]\n",
    "        distances = ((jaccard_distance(set(ngrams(entry,gram_num)),set(ngrams(word,gram_num))),word) for word in words)\n",
    "        closest = min(distances)\n",
    "        recommendations.append(closest[1])\n",
    "    return recommendations# Your answer here\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "Jaccard distance on the 4-grams of the two words.\n",
    "\n",
    "This function should return a list of length three: ['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    gram_num = 4\n",
    "    recommendations = []\n",
    "    for entry in entries:\n",
    "        words = correct_series[correct_series.str.startswith(entry[0])]\n",
    "        distances = ((jaccard_distance(set(ngrams(entry,gram_num)),set(ngrams(word,gram_num))),word) for word in words)\n",
    "        closest = min(distances)\n",
    "        recommendations.append(closest[1])\n",
    "    return recommendations# Your answer here\n",
    "     \n",
    "    \n",
    "    return # Your answer here\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    recommendations = []\n",
    "    for entry in entries:\n",
    "        words = correct_series[correct_series.str.startswith(entry[0])]\n",
    "        distances = ((edit_distance(entry,word),word) for word in words)\n",
    "        closest = min(distances)\n",
    "        recommendations.append(closest[1])\n",
    "    return recommendations# Your answer here\n",
    "     \n",
    "    \n",
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
